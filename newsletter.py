"""
ë‰´ìŠ¤ë ˆí„° ìë™ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸.

RSS í”¼ë“œë‚˜ ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„°ì—ì„œ ì•„í‹°í´ ë§í¬ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•´
Claudeë¡œ ìš”ì•½í•œ ë’¤ ë…¸ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python newsletter.py              # RSS + ì´ë©”ì¼ ì „ì²´ ì²˜ë¦¬
    python newsletter.py --rss        # RSS í”¼ë“œë§Œ ì²˜ë¦¬
    python newsletter.py --email      # ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„°ë§Œ ì²˜ë¦¬
    python newsletter.py --url URL    # ë‹¨ì¼ URL ìˆ˜ë™ ì¶”ê°€

í¬ë¡ íƒ­ ì˜ˆì‹œ (ë§¤ì¼ ì˜¤ì „ 9ì‹œ ìë™ ì‹¤í–‰):
    0 9 * * * cd /path/to/learning-tracker-agent && python newsletter.py >> newsletter.log 2>&1

í™˜ê²½ ë³€ìˆ˜ (.env):
    RSS_FEEDS              - RSS í”¼ë“œ URL (ì‰¼í‘œ êµ¬ë¶„)
    EMAIL_IMAP_SERVER      - IMAP ì„œë²„ (ì˜ˆ: imap.gmail.com)
    EMAIL_ADDRESS          - ì´ë©”ì¼ ì£¼ì†Œ
    EMAIL_APP_PASSWORD     - ì•± ë¹„ë°€ë²ˆí˜¸
    NEWSLETTER_SENDERS     - ë‰´ìŠ¤ë ˆí„° ë°œì‹ ì ì´ë©”ì¼ (ì‰¼í‘œ êµ¬ë¶„)
    EMAIL_DAYS_BACK        - ê²€ìƒ‰ ê¸°ê°„ (ì¼, ê¸°ë³¸ê°’: 7)
"""

import argparse
import imaplib
import email as email_lib
import json
import os
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional
from urllib.parse import urlparse

import google.generativeai as genai
import feedparser
import trafilatura
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from notion_db import NotionDB

load_dotenv()

console = Console()

# ì´ë¯¸ ì²˜ë¦¬í•œ URLì„ ì¶”ì í•˜ëŠ” ë¡œì»¬ íŒŒì¼
PROCESSED_FILE = Path(".processed_urls.json")

# ë…¸ì…˜ì— ì €ì¥í•˜ì§€ ì•Šì„ URL íŒ¨í„´ (êµ¬ë…ì·¨ì†Œ, íŠ¸ë˜í‚¹ íŒŒë¼ë¯¸í„° ë“±)
SKIP_URL_PATTERNS = [
    "unsubscribe", "optout", "opt-out", "mailto:", "tel:",
    ".png", ".jpg", ".jpeg", ".gif", ".webp", ".svg", ".css", ".js",
    "utm_source", "click.sender",
    "twitter.com", "facebook.com", "linkedin.com", "instagram.com",
    "notion.so", "google.com/calendar",
]

# ë‰´ìŠ¤ë ˆí„°ì—ì„œ ì•„í‹°í´ë¡œ ê°„ì£¼í•  ìµœì†Œ URL ê¸¸ì´
MIN_URL_LENGTH = 25


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# URL ì¤‘ë³µ ì¶”ì 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_processed_urls() -> set:
    """ë¡œì»¬ íŒŒì¼ì—ì„œ ì²˜ë¦¬ëœ URL ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if PROCESSED_FILE.exists():
        try:
            data = json.loads(PROCESSED_FILE.read_text(encoding="utf-8"))
            return set(data.get("urls", []))
        except Exception:
            return set()
    return set()


def mark_url_processed(url: str):
    """URLì„ ì²˜ë¦¬ ì™„ë£Œë¡œ ê¸°ë¡í•©ë‹ˆë‹¤."""
    existing = load_processed_urls()
    existing.add(url)
    PROCESSED_FILE.write_text(
        json.dumps({"urls": list(existing)}, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )


def is_article_url(url: str) -> bool:
    """ë‰´ìŠ¤ë ˆí„° ë§í¬ê°€ ì•„í‹°í´ URLì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    if not url or len(url) < MIN_URL_LENGTH:
        return False
    if not url.startswith("http"):
        return False
    return not any(pattern in url.lower() for pattern in SKIP_URL_PATTERNS)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì•„í‹°í´ ì²˜ë¦¬ (Claude ìš”ì•½ â†’ ë…¸ì…˜ ì €ì¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_domain(url: str) -> str:
    """URLì—ì„œ ë„ë©”ì¸ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        parsed = urlparse(url)
        return parsed.netloc.replace("www.", "")
    except Exception:
        return ""


def process_single_article(
    model: genai.GenerativeModel,
    notion: NotionDB,
    url: str,
    hint_title: str = "",
    processed_urls: Optional[set] = None,
) -> bool:
    """
    ë‹¨ì¼ URLì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    1. ì¤‘ë³µ í™•ì¸ (ë¡œì»¬ ìºì‹œ + ë…¸ì…˜ DB)
    2. ë‚´ìš© ì¶”ì¶œ (trafilatura)
    3. Claudeë¡œ ìš”ì•½/íƒœê¹…
    4. ë…¸ì…˜ì— ì €ì¥
    """
    # ë¡œì»¬ ìºì‹œì—ì„œ ì¤‘ë³µ í™•ì¸
    if processed_urls and url in processed_urls:
        console.print(f"  [dim]ê±´ë„ˆëœ€ (ìºì‹œ): {url[:70]}[/dim]")
        return False

    # ë…¸ì…˜ DBì—ì„œ ì¤‘ë³µ í™•ì¸
    if notion.url_exists(url):
        console.print(f"  [dim]ê±´ë„ˆëœ€ (ë…¸ì…˜ì— ìˆìŒ): {url[:70]}[/dim]")
        if processed_urls is not None:
            processed_urls.add(url)
        return False

    # ì•„í‹°í´ ë‚´ìš© ì¶”ì¶œ
    console.print(f"  [dim]ë‚´ìš© ê°€ì ¸ì˜¤ëŠ” ì¤‘: {url[:70]}[/dim]")
    downloaded = trafilatura.fetch_url(url)
    content = ""
    if downloaded:
        content = trafilatura.extract(
            downloaded,
            include_comments=False,
            include_tables=False,
            favor_precision=True,
        ) or ""

    if not content and not hint_title:
        console.print(f"  [yellow]ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨, ê±´ë„ˆëœ€[/yellow]")
        return False

    # Claudeë¡œ ìš”ì•½ ìƒì„±
    content_block = content[:6000] if content else "(ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)"
    prompt = (
        f"ë‹¤ìŒ ì•„í‹°í´ì„ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n\n"
        f"URL: {url}\n"
        f"íŒíŠ¸ ì œëª©: {hint_title or 'ì—†ìŒ'}\n"
        f"ì¶œì²˜: {_get_domain(url)}\n\n"
        f"ë³¸ë¬¸:\n{content_block}\n\n"
        f"ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´):\n"
        f'{{\n'
        f'  "title": "ì•„í‹°í´ ì œëª© (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´)",\n'
        f'  "summary": "ë¬¸ì œ/ìƒí™© 1~2ë¬¸ì¥\\nâˆ™ ê°œë…ëª…: ì„¤ëª…\\nâˆ™ ê°œë…ëª…: ì„¤ëª… (í•µì‹¬ ê°œë… 2~4ê°œ)",\n'
        f'  "key_insights": "PMì´ ê¼­ ì•Œì•„ì•¼ í•  ì : í˜‘ì—…Â·ì„¤ê³„ ì² í•™ ê´€ì  ì‹¤ìš© ì¸ì‚¬ì´íŠ¸ 2~3ë‹¨ë½ (ë‹¨ë½ ì‚¬ì´ \\n\\n, bullet ì•„ë‹Œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥)",\n'
        f'  "tags": ["íƒœê·¸1", "íƒœê·¸2"],\n'
        f'  "source": "ì¶œì²˜ëª… (ì˜ˆ: yozm IT, Medium, arXiv, ì¹´ì¹´ì˜¤í…Œí¬ë¸”ë¡œê·¸)"\n'
        f'}}'
    )

    try:
        response = model.generate_content(prompt)
        raw = response.text.strip()

        # JSON íŒŒì‹± (ì½”ë“œë¸”ë¡ ë˜í•‘ ì œê±°)
        if raw.startswith("```"):
            raw = re.sub(r"^```[a-z]*\n?", "", raw)
            raw = re.sub(r"\n?```$", "", raw)
        data = json.loads(raw)

        notion.add_article(
            title=data.get("title", hint_title or url),
            url=url,
            summary=data.get("summary", ""),
            key_insights=data.get("key_insights", ""),
            tags=data.get("tags", []),
            source=data.get("source", _get_domain(url)),
            status="ì™„ë£Œ",
        )

        mark_url_processed(url)
        if processed_urls is not None:
            processed_urls.add(url)

        console.print(
            f"  [green]âœ“[/green] {data.get('title', url)[:65]}"
        )
        return True

    except json.JSONDecodeError as e:
        console.print(f"  [red]JSON íŒŒì‹± ì˜¤ë¥˜: {e}[/red]")
        return False
    except Exception as e:
        console.print(f"  [red]ì²˜ë¦¬ ì˜¤ë¥˜: {e}[/red]")
        return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RSS í”¼ë“œ ì²˜ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_rss_feeds(
    model: genai.GenerativeModel,
    notion: NotionDB,
    processed_urls: set,
) -> int:
    """RSS í”¼ë“œë¥¼ ì½ì–´ ìƒˆ ì•„í‹°í´ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    feeds_env = os.environ.get("RSS_FEEDS", "").strip()
    if not feeds_env:
        console.print("[yellow]RSS_FEEDSê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/yellow]")
        return 0

    feed_urls = [f.strip() for f in feeds_env.split(",") if f.strip()]
    saved = 0

    for feed_url in feed_urls:
        domain = _get_domain(feed_url)
        console.print(f"\n[bold]ğŸ“¡ RSS:[/bold] {domain} ({feed_url})")

        try:
            feed = feedparser.parse(feed_url)
            if feed.bozo and not feed.entries:
                console.print(f"  [red]í”¼ë“œ ì½ê¸° ì‹¤íŒ¨: {feed.bozo_exception}[/red]")
                continue

            entries = feed.entries[:30]  # ìµœì‹  30ê°œ
            console.print(f"  í•­ëª© {len(entries)}ê°œ ë°œê²¬")

            for entry in entries:
                url = entry.get("link", "")
                title = entry.get("title", "")
                if url and is_article_url(url):
                    if process_single_article(model, notion, url, title, processed_urls):
                        saved += 1

        except Exception as e:
            console.print(f"  [red]í”¼ë“œ ì˜¤ë¥˜: {e}[/red]")

    return saved


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„° ì²˜ë¦¬ (IMAP)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _decode_email_header(header: str) -> str:
    """ì´ë©”ì¼ í—¤ë”ë¥¼ ë””ì½”ë”©í•©ë‹ˆë‹¤."""
    parts = []
    for decoded, charset in email_lib.header.decode_header(header):
        if isinstance(decoded, bytes):
            parts.append(decoded.decode(charset or "utf-8", errors="ignore"))
        else:
            parts.append(decoded)
    return "".join(parts)


def extract_urls_from_email(msg) -> list:
    """ì´ë©”ì¼ ë©”ì‹œì§€ì—ì„œ ì•„í‹°í´ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    found = []

    for part in msg.walk():
        content_type = part.get_content_type()
        payload = part.get_payload(decode=True)
        if not payload:
            continue

        text = payload.decode("utf-8", errors="ignore")

        if content_type == "text/html":
            soup = BeautifulSoup(text, "html.parser")
            for a_tag in soup.find_all("a", href=True):
                href = a_tag["href"].strip()
                if is_article_url(href):
                    found.append(href)

        elif content_type == "text/plain":
            pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
            for url in re.findall(pattern, text):
                if is_article_url(url):
                    found.append(url)

    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    return list(dict.fromkeys(found))


def process_email_newsletters(
    model: genai.GenerativeModel,
    notion: NotionDB,
    processed_urls: set,
) -> int:
    """IMAPì„ í†µí•´ ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì½ì–´ ì•„í‹°í´ URLì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    imap_server = os.environ.get("EMAIL_IMAP_SERVER", "").strip()
    email_addr = os.environ.get("EMAIL_ADDRESS", "").strip()
    app_password = os.environ.get("EMAIL_APP_PASSWORD", "").strip()
    senders_env = os.environ.get("NEWSLETTER_SENDERS", "").strip()
    days_back = int(os.environ.get("EMAIL_DAYS_BACK", "7"))

    if not all([imap_server, email_addr, app_password]):
        console.print(
            "[yellow]ì´ë©”ì¼ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤ "
            "(EMAIL_IMAP_SERVER, EMAIL_ADDRESS, EMAIL_APP_PASSWORD).[/yellow]"
        )
        return 0

    senders = [s.strip() for s in senders_env.split(",") if s.strip()]
    if not senders:
        console.print("[yellow]NEWSLETTER_SENDERSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/yellow]")
        return 0

    saved = 0
    since_date = (datetime.now() - timedelta(days=days_back)).strftime("%d-%b-%Y")

    console.print(f"\n[bold]ğŸ“§ ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„° ì²˜ë¦¬[/bold] (ìµœê·¼ {days_back}ì¼)")

    try:
        mail = imaplib.IMAP4_SSL(imap_server)
        mail.login(email_addr, app_password)
        mail.select("INBOX")

        for sender in senders:
            console.print(f"\n  ë°œì‹ ì: [cyan]{sender}[/cyan]")

            # IMAP ê²€ìƒ‰: íŠ¹ì • ë°œì‹ ì + ë‚ ì§œ ì´í›„
            _, data = mail.search(None, f'FROM "{sender}" SINCE "{since_date}"')
            email_ids = data[0].split() if data[0] else []
            console.print(f"  ì´ë©”ì¼ {len(email_ids)}ê°œ ë°œê²¬")

            for eid in email_ids:
                _, msg_data = mail.fetch(eid, "(RFC822)")
                raw_msg = msg_data[0][1]
                msg = email_lib.message_from_bytes(raw_msg)

                subject = _decode_email_header(msg.get("Subject", ""))
                console.print(f"\n  ğŸ“¨ {subject[:60]}")

                urls = extract_urls_from_email(msg)
                console.print(f"  URL {len(urls)}ê°œ ì¶”ì¶œ")

                for url in urls:
                    if process_single_article(model, notion, url, "", processed_urls):
                        saved += 1

        mail.logout()

    except imaplib.IMAP4.error as e:
        console.print(f"\n[red]IMAP ì˜¤ë¥˜: {e}[/red]")
        console.print(
            "[dim]Gmail ì‚¬ìš© ì‹œ 'ì•± ë¹„ë°€ë²ˆí˜¸'ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
            "ì¼ë°˜ ë¹„ë°€ë²ˆí˜¸ëŠ” ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.[/dim]"
        )
    except Exception as e:
        console.print(f"\n[red]ì˜¤ë¥˜: {e}[/red]")

    return saved


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì§„ì…ì 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="ë‰´ìŠ¤ë ˆí„°ì—ì„œ ì•„í‹°í´ì„ ìë™ìœ¼ë¡œ ë…¸ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤."
    )
    parser.add_argument("--rss", action="store_true", help="RSS í”¼ë“œë§Œ ì²˜ë¦¬")
    parser.add_argument("--email", action="store_true", help="ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„°ë§Œ ì²˜ë¦¬")
    parser.add_argument("--url", metavar="URL", help="ë‹¨ì¼ URL ìˆ˜ë™ ì¶”ê°€")
    args = parser.parse_args()

    # --url, --rss, --email ëª¨ë‘ ì—†ìœ¼ë©´ ì „ì²´ ì‹¤í–‰
    run_all = not any([args.rss, args.email, args.url])

    for var in ["GEMINI_API_KEY", "NOTION_TOKEN", "NOTION_DATABASE_ID"]:
        if not os.environ.get(var):
            console.print(f"[red]ì˜¤ë¥˜: {var}ê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/red]")
            return

    genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
    model = genai.GenerativeModel("gemini-2.0-flash")
    notion = NotionDB()
    processed_urls = load_processed_urls()

    console.print(
        Panel.fit(
            f"[bold]ğŸ—ï¸  ë‰´ìŠ¤ë ˆí„° ìë™ ì²˜ë¦¬[/bold]\n"
            f"[dim]{datetime.now().strftime('%Y-%m-%d %H:%M')} | "
            f"ì²˜ë¦¬ ì™„ë£Œ ìºì‹œ: {len(processed_urls)}ê°œ[/dim]",
            style="blue",
        )
    )

    total = 0

    # ë‹¨ì¼ URL ìˆ˜ë™ ì¶”ê°€
    if args.url:
        console.print(f"\n[bold]ğŸ”— ìˆ˜ë™ URL ì¶”ê°€[/bold]")
        if process_single_article(model, notion, args.url, "", processed_urls):
            total += 1

    # RSS í”¼ë“œ ì²˜ë¦¬
    if args.rss or run_all:
        total += process_rss_feeds(model, notion, processed_urls)

    # ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„° ì²˜ë¦¬
    if args.email or run_all:
        total += process_email_newsletters(model, notion, processed_urls)

    # ê²°ê³¼ ìš”ì•½
    console.print()
    if total > 0:
        console.print(
            f"[bold green]âœ… ì™„ë£Œ! ìƒˆë¡œ ì €ì¥ëœ ì•„í‹°í´: {total}ê°œ[/bold green]"
        )
    else:
        console.print("[dim]ìƒˆë¡œ ì €ì¥ëœ ì•„í‹°í´ì´ ì—†ìŠµë‹ˆë‹¤.[/dim]")

    console.print(
        f"[dim]í¬ë¡ íƒ­ ì„¤ì •: 0 9 * * * cd $(pwd) && python newsletter.py[/dim]"
    )


if __name__ == "__main__":
    main()
